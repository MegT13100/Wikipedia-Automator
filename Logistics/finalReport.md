*all photos referenced are in the reportPhotos folder

Our project set out to automate the Wikipedia Game, an online game where someone picks the name of a Wikipedia article. Each person then starts on a different, randomized article and tries to be the first one to get to the specific article, just using Wikipedia hyperlinks. Using a dataset of Wikipedia articles and links, we have written a Breadth-First Search algorithm that finds the shortest path between any two articles, and prints out the names of the articles between the start and end articles. (The output shown in BFSFakeData.png is on our trial data, as it is easier to understand the output.)

Secondly, we set out to find some of the “important” or well-connected Wikipedia articles using the PageRank algorithm. Unfortunately, due to the run time of PageRank and of our visualization algorithm, it was impossible to use the full Wikipedia dataset. Within the 5000 points we had, we found that an article about Buprestidae ranked the highest, which was surprising. In the file PageRank50.png,  you can see an output from the algorithm of the top 50 pages.

Lastly, we set out to visualize the hyperlinks using a Fructerman-Reingold force-directed layout.  For the visualizations below, the maximum number of iterations was set to 30,  the ideal length of the edges to 101, and the cooling factor to 1. We found that with our dataset, if the algorithm was “cooled” at all, it would not move the points. To figure out the best possible input combinations would take more trial and error, however, we found this combination worked well and provided two different graphs, where one had a better layout than the other.  Due to our dataset not being able to run at full-scale, our output contains points that are unconnected to the rest of the graph. We can only assume that they would be connected all 1 million plus nodes were added. An intitial layout can be found in the png of a similar name, where the positions of the nodes were randomly placed. The force-directed visualization is found in the ForceDirectedLayout.png, where the graph has been “untangled” and some of the points lie closer to the central node. 

Our implementation of the PageRank algorithm was successful in ranking different Wikipedia pages with respect to their prevalence in the graph database. Similar to how Google utilized the PageRank algorithm, we observed that nodes (Wikipedia pages) with the most inbound links (edges) from other prevalent (high ranking) nodes proved to be at the top of the rankings. Through the implementation, we discovered that we were able to put weights on these nodes, much like how weighted graphs put weights on the edges. Since our dataset was a directed, unweighted graph dataset, this was especially useful and insightful to see which of our data points would be most substantial. By seeing which of the data points were the most prevalent, people utilizing our program could use this insight to truly understand why certain links provide the shortest path from one page to another. As seen in the PageRank data above, we were able to run our algorithm on the Wikipedia top categories dataset of 5000 nodes. We limited the results to 50 as it was too long of a list to visualize every one of the node’s ranking and PageRank values.


